{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f725580b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# Titanic - Binary Classification\n",
    "# Author: Yassine KHERBOUCHE (@yassinemimis)\n",
    "# =============================================================\n",
    "\n",
    "# ── 1. IMPORTS ───────────────────────────────────────────────\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (classification_report, confusion_matrix,\n",
    "                             f1_score, roc_auc_score)\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reproducibility\n",
    "import random\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "#2. LOAD DATA \n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df  = pd.read_csv('../data/test.csv')\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape :\", test_df.shape)\n",
    "train_df.head()\n",
    "\n",
    "# 3. EXPLORATORY DATA ANALYSIS \n",
    "print(\"\\nMissing values:\\n\", train_df.isnull().sum())\n",
    "print(\"\\nSurvival rate:\", train_df['Survived'].mean().round(3))\n",
    "\n",
    "# Survival by Sex\n",
    "sns.barplot(x='Sex', y='Survived', data=train_df)\n",
    "plt.title('Survival Rate by Sex')\n",
    "plt.savefig('../data/survival_by_sex.png')\n",
    "plt.show()\n",
    "\n",
    "# 4. PREPROCESSING\n",
    "def preprocess(df, is_train=True):\n",
    "    df = df.copy()\n",
    "\n",
    "    # 4.1 Fill missing Age with median\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "    # 4.2 Fill missing Embarked with mode\n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "\n",
    "    # 4.3 Fill missing Fare with median\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "\n",
    "    # 4.4 Feature Engineering\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone']    = (df['FamilySize'] == 1).astype(int)\n",
    "    df['Title']      = df['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "    df['Title']      = df['Title'].replace(\n",
    "        ['Lady','Countess','Capt','Col','Don','Dr',\n",
    "         'Major','Rev','Sir','Jonkheer','Dona'], 'Rare')\n",
    "    df['Title']      = df['Title'].replace({'Mlle':'Miss',\n",
    "                                            'Ms':'Miss',\n",
    "                                            'Mme':'Mrs'})\n",
    "\n",
    "    # 4.5 Encode categoricals\n",
    "    le = LabelEncoder()\n",
    "    df['Sex']      = le.fit_transform(df['Sex'])\n",
    "    df['Embarked'] = le.fit_transform(df['Embarked'])\n",
    "    df['Title']    = le.fit_transform(df['Title'])\n",
    "\n",
    "    # 4.6 Select features\n",
    "    features = ['Pclass','Sex','Age','Fare','Embarked',\n",
    "                'FamilySize','IsAlone','Title']\n",
    "    X = df[features]\n",
    "\n",
    "    if is_train:\n",
    "        y = df['Survived']\n",
    "        return X, y\n",
    "    return X\n",
    "\n",
    "X, y = preprocess(train_df, is_train=True)\n",
    "X_test_final = preprocess(test_df, is_train=False)\n",
    "\n",
    "# 5. TRAIN / VAL SPLIT\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_val_s   = scaler.transform(X_val)\n",
    "\n",
    "#6. MODEL SELECTION \n",
    "# Why RandomForest over LogisticRegression and SVM?\n",
    "# - Handles non-linear relationships (Age*Pclass interaction)\n",
    "# - Robust to outliers in Fare\n",
    "# - Built-in feature importance\n",
    "# Alternatives considered: LogisticRegression (too linear),\n",
    "#                          SVM (sensitive to scale, slower)\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200,      # tuned: range [50, 500]\n",
    "    max_depth=6,           # most impactful: range [3, 10]\n",
    "    min_samples_split=4,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "model.fit(X_train_s, y_train)\n",
    "\n",
    "# 7. EVALUATION \n",
    "y_pred = model.predict(X_val_s)\n",
    "y_prob = model.predict_proba(X_val_s)[:, 1]\n",
    "\n",
    "print(\"\\n── Validation Results ──────────────────────────\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"F1  Score :\", f1_score(y_val, y_pred).round(4))\n",
    "print(\"ROC-AUC   :\", roc_auc_score(y_val, y_prob).round(4))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Not Survived','Survived'],\n",
    "            yticklabels=['Not Survived','Survived'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('../data/confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "#  8. ERROR ANALYSIS\n",
    "val_df = X_val.copy()\n",
    "val_df['y_true'] = y_val.values\n",
    "val_df['y_pred'] = y_pred\n",
    "\n",
    "# False Negatives: survived but predicted dead\n",
    "fn = val_df[(val_df['y_true']==1) & (val_df['y_pred']==0)]\n",
    "print(\"\\nFalse Negatives (survived → predicted dead):\")\n",
    "print(fn[['Pclass','Sex','Age','FamilySize']].head(5))\n",
    "\n",
    "# 9. CROSS-VALIDATION \n",
    "cv_scores = cross_val_score(model, X_train_s, y_train,\n",
    "                            cv=5, scoring='f1')\n",
    "print(\"\\n5-Fold CV F1:\", cv_scores.round(4))\n",
    "print(\"Mean F1     :\", cv_scores.mean().round(4))\n",
    "\n",
    "#10. FEATURE IMPORTANCE\n",
    "feat_imp = pd.Series(model.feature_importances_,\n",
    "                     index=X.columns).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/feature_importance.png')\n",
    "plt.show()\n",
    "\n",
    "#  11. SAVE MODEL\n",
    "import joblib\n",
    "joblib.dump(model,  '../data/rf_titanic_v1.pkl')\n",
    "joblib.dump(scaler, '../data/scaler_v1.pkl')\n",
    "print(\"\\nModel saved: rf_titanic_v1.pkl\")\n",
    "print(\"Checkpoint : rf_titanic_v1.pkl | F1=\", \n",
    "      f1_score(y_val, y_pred).round(4))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
